# ğŸ” RAG with DeepSeek & Ollama ğŸ¤–

This repository implements **Retrieval-Augmented Generation (RAG)** using **DeepSeek** with **Ollama**, ensuring all data is processed and stored **locally** for privacy and security.

## âœ¨ Features
âœ… **Retrieval-Augmented Generation (RAG)** pipeline  
âœ… **DeepSeek + Ollama** integration for efficient LLM inference  
âœ… **Fully Local Setup** â€“ No external API calls, ensuring data privacy  
âœ… **FAISS / ChromaDB** for local vector storage and fast retrieval if needed ofr In memory Storage
âœ… Example use cases and real-world applications  

---

## ğŸ›  Tech Stack  
ğŸš€ **Ollama** - Local LLM execution  
ğŸ¤– **DeepSeek** - Powerful Large Language Model (LLM)  
ğŸ“– **LangChain** - Framework for LLM-powered applications  
ğŸ” **FAISS / ChromaDB** - Local vector database for retrieval if needed
ğŸ **Python** - Core language for implementation  

---

## ğŸš€ Getting Started

### ğŸ”¹ Clone the Repository  
```bash
git clone https://github.com/Satyajit-Chaudhuri/Generative-AI.git
cd Generative-AI/RagwithDeepseek
